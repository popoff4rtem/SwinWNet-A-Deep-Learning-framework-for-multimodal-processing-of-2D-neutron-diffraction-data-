name: Build & Release InferenceGUI

on:
  push:
    tags:
      - "v*"
  workflow_dispatch:

permissions:
  contents: write

jobs:
  build:
    strategy:
      fail-fast: false
      matrix:
        os: [windows-latest, ubuntu-latest, macos-15]
    runs-on: ${{ matrix.os }}

    steps:
      - name: Enable long paths (Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          git config --global core.longpaths true

      - name: Checkout (sparse, short path)
        uses: actions/checkout@v4
        with:
          fetch-depth: 1
          path: r
          sparse-checkout: |
            inference_gui/
            SwinWNet.py
            ST_Inference_Pipline.py
            SwinWNet/
            .github/
          sparse-checkout-cone-mode: false

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        working-directory: r
        shell: bash
        run: |
          python -m pip install --upgrade pip
          pip install numpy matplotlib pyside6 pyinstaller

          if [[ "${{ runner.os }}" == "Linux" ]]; then
            echo "Installing CPU-only torch for Linux"
            pip install --index-url https://download.pytorch.org/whl/cpu torch
          else
            echo "Installing default torch"
            pip install torch
          fi

      - name: Build (onedir)
        working-directory: r
        run: |
          pyinstaller inference_gui/swinwnet_viewer_gui.py \
            --noconfirm --clean --onedir --windowed \
            --name InferenceGUI \
            --hidden-import=matplotlib.backends.backend_qtagg \
            --hidden-import=PySide6.QtCore \
            --hidden-import=PySide6.QtGui \
            --hidden-import=PySide6.QtWidgets \
            --hidden-import=SwinWNet \
            --hidden-import=ST_Inference_Pipline \
            --collect-all torch

      - name: Pack zip (Windows)
        if: runner.os == 'Windows'
        working-directory: r
        shell: pwsh
        run: |
          Compress-Archive -Path dist/InferenceGUI -DestinationPath InferenceGUI_${{ runner.os }}_${{ github.ref_name }}.zip

      - name: Pack (Linux) tar.zst and split if needed
        if: runner.os == 'Linux'
        working-directory: r
        shell: bash
        run: |
          sudo apt-get update
          sudo apt-get install -y zstd

          OUT="InferenceGUI_${{ runner.os }}_CPU_${{ github.ref_name }}.tar.zst"
          echo "Packing to $OUT ..."
          tar -C dist -cf - InferenceGUI | zstd -19 -T0 -o "$OUT"

          ls -lh "$OUT"
          SIZE=$(stat -c%s "$OUT")
          echo "Size bytes: $SIZE"

          # If >= 2GB -> split into ~1900MB parts
          if [ "$SIZE" -ge 2147483648 ]; then
            echo "Asset >=2GB, splitting..."
            split -b 1900m -d -a 2 "$OUT" "${OUT}.part"
            rm -f "$OUT"
            ls -lh "${OUT}.part"* | head
          fi

      - name: Pack zip (macOS)
        if: runner.os == 'macOS'
        working-directory: r
        shell: bash
        run: |
          zip -r "InferenceGUI_${{ runner.os }}_${{ github.ref_name }}.zip" dist/InferenceGUI

      - name: Upload to Release (Linux)
        if: runner.os == 'Linux'
        uses: softprops/action-gh-release@v2
        with:
          files: |
            r/InferenceGUI_Linux_CPU_${{ github.ref_name }}.tar.zst
            r/InferenceGUI_Linux_CPU_${{ github.ref_name }}.tar.zst.part*

      - name: Upload to Release (Windows/macOS)
        if: runner.os != 'Linux'
        uses: softprops/action-gh-release@v2
        with:
          files: r/InferenceGUI_${{ runner.os }}_${{ github.ref_name }}.zip
